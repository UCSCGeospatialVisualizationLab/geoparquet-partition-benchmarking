# Results Directory

This directory stores all performance test results and measurement data.

## ðŸŽ‰ Latest Results Summary

### âœ… Analytical Benchmark Complete (2025-08-12)
**File**: `analytical_benchmark_20250812_100506.json`

| Strategy | Total Time | Peak Memory | Best For |
|----------|------------|-------------|----------|
| **ATTRIBUTE_STATE** | **33.93s** âš¡ | 30.7MB | State-based analytics |
| **NO_PARTITION** | 119.59s | 58.4MB | Simple queries |
| **HYBRID_STATE_H3** | 241.42s | **27.8MB** ðŸ’¾ | Mixed workloads |
| **SPATIAL_H3_L3** | 405.05s | 30.2MB | Spatial-heavy queries |

**Key Finding**: Attribute-based partitioning provides **3.5x better performance** than no partitioning for analytical workloads.

### âœ… Visualization Clients Complete
**Status**: All 3 clients functional and tested
- **Arrow.js + parquet-wasm**: Real Parquet parsing âœ…
- **Hyparquet**: Progressive streaming âœ…  
- **DuckDB-WASM**: Spatial SQL queries âœ…

### âœ… S3 Data Architecture Complete
**Files**: `s3_bucket_setup.json`, `s3_data_exploration.json`, `partitioning_results.json`, `h3_hexagon_discovery.json`
- **Dataset**: 85,141 census tracts (1.52GB)
- **Partitioning**: 4 strategies implemented and tested
- **H3 Discovery**: Working hexagons identified for Bay Area testing

## Directory Structure

```
results/
â”œâ”€â”€ raw_data/              # Raw performance measurements
â”‚   â”œâ”€â”€ analytics/         # DuckDB query performance data
â”‚   â”œâ”€â”€ visualization/     # Client-side performance data
â”‚   â””â”€â”€ network/          # HTTP request patterns and metrics
â”œâ”€â”€ processed/            # Cleaned and aggregated results
â”œâ”€â”€ comparisons/          # Cross-strategy performance comparisons
â”œâ”€â”€ reports/              # Generated performance reports
â””â”€â”€ exports/              # Data exports for external analysis
```

## Data Formats

### Analytics Results
- **Query Performance**: JSON files with execution times, resource usage
- **S3 Request Patterns**: CSV files with request counts, data transfer volumes
- **Resource Utilization**: Time-series data for CPU, memory, I/O

### Visualization Results  
- **Client Performance**: JSON files with loading times, rendering metrics
- **Network Transfer**: CSV files with bytes transferred, request patterns
- **Progressive Loading**: Time-series data for incremental data arrival

### Comparative Analysis
- **Cross-Strategy Comparisons**: Aggregated performance across partitioning strategies
- **Client Comparisons**: Performance differences between Arrow, Hyparquet, DuckDB-WASM
- **Network Impact**: Performance under different bandwidth/latency conditions

## File Naming Convention

```
{test_type}_{partition_strategy}_{client_type}_{timestamp}.{format}

Examples:
- analytics_spatial_h3_l4_duckdb_20240315_143022.json
- visualization_no_partition_arrow_20240315_143045.json  
- network_hybrid_state_h3_hyparquet_20240315_143108.csv
```

## Usage

Results are automatically generated by the benchmark runner. Key files:

- `benchmark_summary.json` - Overall test run summary
- `comparative_analysis.html` - Interactive performance comparison dashboard  
- `raw_measurements/` - Detailed raw data for custom analysis

## Analysis

Use scripts in the `analysis/` directory to process and visualize results:

```bash
# Generate comparative report
python analysis/generate_report.py

# Create performance visualizations  
python analysis/create_charts.py

# Export data for external tools
python analysis/export_data.py --format csv
```