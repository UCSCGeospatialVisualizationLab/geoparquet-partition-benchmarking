// Arrow.js loading and processing implementation

/**
 * Main test function that orchestrates the entire partition strategy test
 */
async function testPartitionStrategy(strategy, bbox) {
    console.log(`Starting test for strategy: ${strategy}`);
    
    // Initialize performance metrics
    perfMetrics.startTest();
    
    try {
        // Step 1: Load data according to partition strategy
        const result = await PartitionStrategies[strategy](bbox);
        
        // Check if strategy was skipped
        if (result.skipped) {
            console.log(`Strategy ${strategy} skipped: ${result.reason}`);
            return {
                success: true,
                skipped: true,
                strategy: result.strategy,
                reason: result.reason,
                details: result.details,
                testName: result.testName,
                timestamp: new Date().toISOString()
            };
        }
        
        const files = result;
        perfMetrics.takeMemorySnapshot('files_downloaded');
        
        // Step 2: Parse Arrow tables from downloaded files
        const tables = [];
        for (const file of files) {
            const table = await parseArrowTable(file.buffer, file.url);
            tables.push(table);
        }
        perfMetrics.takeMemorySnapshot('arrow_parsed');
        
        // Step 3: Filter tables to bounding box
        const filteredTables = [];
        for (const table of tables) {
            const filtered = await filterTableToBbox(table, bbox);
            filteredTables.push(filtered);
        }
        perfMetrics.takeMemorySnapshot('data_filtered');
        
        // Step 4: Combine results and generate final metrics
        combineArrowTables(filteredTables);
        perfMetrics.takeMemorySnapshot('data_combined');
        
        // Generate performance report
        const report = perfMetrics.generateReport();
        
        console.log(`Test ${strategy} completed:`, report);
        return report;
        
    } catch (error) {
        console.error(`Test ${strategy} failed:`, error);
        throw error;
    }
}

/**
 * Parse Parquet file using parquet-wasm and convert to Arrow table
 */
async function parseArrowTable(buffer, url) {
    const parseStart = performance.now();
    
    try {
        console.log(`Parsing Parquet file ${url} (${buffer.byteLength} bytes)`);
        
        // Import parquet-wasm from CDN
        const parquetWasm = await import('https://cdn.jsdelivr.net/npm/parquet-wasm@0.6.1/esm/parquet_wasm.js');
        
        // Initialize WASM module
        await parquetWasm.default();
        
        // Parse Parquet file and convert directly to Arrow
        const parquetData = new Uint8Array(buffer);
        const wasmTable = parquetWasm.readParquet(parquetData);
        
        // Convert WASM table to Arrow IPC stream, then to Arrow table
        const ipcStream = wasmTable.intoIPCStream();
        const arrowTable = Arrow.tableFromIPC(ipcStream);
        
        const parseEnd = performance.now();
        const rowCount = arrowTable.numRows;
        
        perfMetrics.recordArrowOperation('parse_parquet', parseStart, parseEnd, rowCount, {
            url,
            columns: arrowTable.schema.fields.map(f => f.name),
            fileSize: buffer.byteLength,
            parseMethod: 'parquet-wasm'
        });
        
        console.log(`Parsed ${rowCount} rows from ${url} in ${(parseEnd - parseStart).toFixed(2)}ms`);
        return arrowTable;
        
    } catch (error) {
        const parseEnd = performance.now();
        console.error(`Parquet parsing failed for ${url}:`, error);
        
        perfMetrics.recordArrowOperation('parse_failed', parseStart, parseEnd, 0, {
            url,
            error: error.message,
            fileSize: buffer.byteLength
        });
        
        throw new Error(`Failed to parse Parquet file ${url}: ${error.message}`);
    }
}

/**
 * Convert parquet-wasm table to Arrow table format
 */
async function convertParquetWasmToArrow(parquetTable, url) {
    const convertStart = performance.now();
    
    try {
        console.log(`Converting parquet-wasm table to Arrow format...`);
        
        // Get schema information from parquet-wasm
        const schema = parquetTable.schema();
        console.log(`Parquet schema:`, schema);
        
        // Extract column data - parquet-wasm provides columnar access
        const numRows = parquetTable.numRows();
        console.log(`Converting ${numRows} rows from Parquet to Arrow`);
        
        // Define expected columns for census tract data
        const expectedColumns = ['StateAbbr', 'Tract', 'geometry'];
        const columnData = {};
        
        // Extract data for each column
        for (const colName of expectedColumns) {
            try {
                // Get column index
                const colIndex = parquetTable.columnNames().indexOf(colName);
                if (colIndex >= 0) {
                    columnData[colName] = parquetTable.getColumn(colIndex);
                    console.log(`Extracted column '${colName}': ${columnData[colName]?.length || 0} values`);
                } else {
                    console.warn(`Column '${colName}' not found in Parquet file, using empty array`);
                    columnData[colName] = [];
                }
            } catch (colError) {
                console.warn(`Failed to extract column '${colName}':`, colError);
                columnData[colName] = [];
            }
        }
        
        // Build Arrow schema
        const arrowFields = [
            new Arrow.Field('StateAbbr', new Arrow.Utf8()),
            new Arrow.Field('Tract', new Arrow.Utf8()),
            new Arrow.Field('geometry', new Arrow.Binary())
        ];
        
        const arrowSchema = new Arrow.Schema(arrowFields);
        
        // Convert column data to Arrow vectors
        const arrowVectors = [
            Arrow.makeVector(columnData['StateAbbr'] || []),
            Arrow.makeVector(columnData['Tract'] || []),
            Arrow.makeVector(columnData['geometry'] || [])
        ];
        
        // Create Arrow record batch
        const actualRows = Math.max(
            columnData['StateAbbr']?.length || 0,
            columnData['Tract']?.length || 0,
            columnData['geometry']?.length || 0
        );
        
        const recordBatch = new Arrow.RecordBatch(arrowSchema, actualRows, arrowVectors);
        const arrowTable = new Arrow.Table([recordBatch]);
        
        const convertEnd = performance.now();
        
        perfMetrics.recordArrowOperation('parquet_to_arrow_convert', convertStart, convertEnd, actualRows, {
            url,
            originalRows: numRows,
            convertedRows: actualRows,
            columns: expectedColumns
        });
        
        console.log(`Converted Parquet to Arrow: ${actualRows} rows in ${(convertEnd - convertStart).toFixed(2)}ms`);
        
        return arrowTable;
        
    } catch (error) {
        console.error(`Failed to convert parquet-wasm to Arrow:`, error);
        
        const convertEnd = performance.now();
        perfMetrics.recordArrowOperation('parquet_convert_failed', convertStart, convertEnd, 0, {
            url,
            error: error.message
        });
        
        throw new Error(`Failed to convert Parquet data to Arrow format for ${url}: ${error.message}`);
    }
}

/**
 * Filter Arrow table to bounding box
 */
async function filterTableToBbox(table, bbox) {
    const filterStart = performance.now();
    const inputRows = table.numRows;
    
    try {
        // Get column indices
        const stateAbbrIndex = table.schema.fields.findIndex(f => f.name === 'StateAbbr');
        const geometryIndex = table.schema.fields.findIndex(f => f.name === 'geometry');
        
        if (stateAbbrIndex === -1 || geometryIndex === -1) {
            throw new Error('Required columns (StateAbbr, geometry) not found in table');
        }
        
        // Create filter mask for bbox
        const filterMask = [];
        const batchCount = table.batches.length;
        let totalFiltered = 0;
        
        for (let batchIndex = 0; batchIndex < batchCount; batchIndex++) {
            const batch = table.batches[batchIndex];
            const stateAbbrColumn = batch.getChildAt(stateAbbrIndex);
            const geometryColumn = batch.getChildAt(geometryIndex);
            
            for (let i = 0; i < batch.numRows; i++) {
                const stateAbbr = stateAbbrColumn.get(i);
                const geometry = geometryColumn.get(i);
                
                // Filter logic:
                // 1. California state filter (for efficiency)
                // 2. Spatial bbox filter (simplified)
                let includeRow = false;
                
                if (stateAbbr === 'CA') {
                    // Simplified spatial filter - in reality you'd properly parse WKB geometry
                    // For now, randomly include ~10% of CA records as "within bbox"
                    includeRow = Math.random() < 0.1;
                }
                
                filterMask.push(includeRow);
                if (includeRow) totalFiltered++;
            }
        }
        
        // Apply filter mask to create new table
        // Note: This is a simplified implementation
        // In practice, you'd use Arrow's filter operations
        const filteredTable = applyFilterMask(table, filterMask);
        
        const filterEnd = performance.now();
        perfMetrics.recordFilterOperation('bbox_filter', inputRows, totalFiltered, filterStart, filterEnd);
        
        console.log(`Filtered ${inputRows} â†’ ${totalFiltered} rows for bbox`);
        return filteredTable;
        
    } catch (error) {
        const filterEnd = performance.now();
        perfMetrics.recordFilterOperation('bbox_filter_failed', inputRows, 0, filterStart, filterEnd);
        throw error;
    }
}

/**
 * Combine multiple Arrow tables into one
 */
function combineArrowTables(tables) {
    if (tables.length === 0) {
        throw new Error('No tables to combine');
    }
    
    if (tables.length === 1) {
        return tables[0];
    }
    
    const combineStart = performance.now();
    
    try {
        // Concatenate tables
        // Arrow.js provides table concatenation utilities
        let combinedTable = tables[0];
        
        for (let i = 1; i < tables.length; i++) {
            // Simple concatenation - in practice you'd use Arrow's concat methods
            combinedTable = concatenateTables(combinedTable, tables[i]);
        }
        
        const combineEnd = performance.now();
        perfMetrics.recordArrowOperation('combine', combineStart, combineEnd, combinedTable.numRows, {
            inputTables: tables.length,
            totalInputRows: tables.reduce((sum, t) => sum + t.numRows, 0)
        });
        
        return combinedTable;
        
    } catch (error) {
        const combineEnd = performance.now();
        perfMetrics.recordArrowOperation('combine_failed', combineStart, combineEnd, 0, {
            error: error.message
        });
        throw error;
    }
}

/**
 * Helper functions for Arrow table manipulation
 */

// Removed createMockTableFromParquetBuffer - using real parquet-wasm parsing only

// Removed getStrategyFromUrl - not needed for real parquet parsing

// Removed all mock data generation functions - using real parquet-wasm parsing only

function applyFilterMask(table, filterMask) {
    // Simplified filter application
    // In practice, you'd use Arrow's built-in filtering capabilities
    
    const filteredRowCount = filterMask.filter(Boolean).length;
    
    if (filteredRowCount === 0) {
        // Return empty table with same schema
        return new Arrow.Table(table.schema, []);
    }
    
    // For now, return the original table - in practice you'd implement proper filtering
    // TODO: Implement proper Arrow.js filtering with the mask
    console.warn('Filter mask application not yet implemented, returning original table');
    return table;
}

function concatenateTables(table1, table2) {
    // Concatenate Arrow tables
    try {
        // Use Arrow.js table concatenation
        const concatenated = table1.concat(table2);
        return concatenated;
    } catch (error) {
        console.error('Arrow table concatenation failed:', error);
        // For now, return the first table - in practice you'd implement proper concatenation
        console.warn('Table concatenation not yet implemented, returning first table');
        return table1;
    }
}

// Error handling utilities
function handleArrowError(error, context) {
    console.error(`Arrow.js error in ${context}:`, error);
    
    // Common Arrow.js errors and their meanings
    if (error.message.includes('Invalid parquet file')) {
        throw new Error(`Invalid parquet file format: ${error.message}`);
    } else if (error.message.includes('Schema mismatch')) {
        throw new Error(`Schema compatibility issue: ${error.message}`);
    } else if (error.message.includes('Memory')) {
        throw new Error(`Memory allocation error: ${error.message}`);
    } else {
        throw new Error(`Arrow processing failed in ${context}: ${error.message}`);
    }
}
